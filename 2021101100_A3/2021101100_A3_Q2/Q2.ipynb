{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, bottleneck_dims=64):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, bottleneck_dims, 7)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, bottleneck_dims=64):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(bottleneck_dims, 32, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, bottleneck_dims=64):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder(bottleneck_dims=bottleneck_dims)\n",
    "        self.decoder = Decoder(bottleneck_dims=bottleneck_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, num_epochs=10, sigma=0.1):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\", unit='batch') as pbar:\n",
    "            for data in train_loader:\n",
    "                img, _ = data\n",
    "                noisy_img = img + torch.randn_like(img) * sigma\n",
    "                noisy_img = torch.clamp(noisy_img, 0., 1.)  # clip to range [0, 1]\n",
    "                optimizer.zero_grad()\n",
    "                recon = model(noisy_img)\n",
    "                loss = criterion(recon, img)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({'Loss': loss.item()})\n",
    "\n",
    "# Testing function\n",
    "def test(model, test_loader, sigma=0.1):\n",
    "    model.eval()\n",
    "    ssim_score = 0\n",
    "    total_images = 0\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(test_loader), desc=f\"Testing\", unit='batch') as pbar:\n",
    "            for data in test_loader:\n",
    "                img, _ = data\n",
    "                noisy_img = img + torch.randn_like(img) * sigma\n",
    "                noisy_img = torch.clamp(noisy_img, 0., 1.)  # clip to range [0, 1]\n",
    "                recon = model(noisy_img)\n",
    "                ssim_score += np.sum([ssim(img[i, 0].numpy(), recon[i, 0].numpy(), data_range=1) for i in range(img.shape[0])])\n",
    "                total_images += img.shape[0]\n",
    "                pbar.update(1)\n",
    "                \n",
    "    return ssim_score / total_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 938/938 [00:32<00:00, 28.87batch/s, Loss=0.00241]\n",
      "Epoch 2/10: 100%|██████████| 938/938 [00:34<00:00, 27.15batch/s, Loss=0.00277]\n",
      "Epoch 3/10: 100%|██████████| 938/938 [00:34<00:00, 27.39batch/s, Loss=0.00262]\n",
      "Epoch 4/10: 100%|██████████| 938/938 [00:33<00:00, 27.70batch/s, Loss=0.00256]\n",
      "Epoch 5/10: 100%|██████████| 938/938 [00:35<00:00, 26.29batch/s, Loss=0.00295]\n",
      "Epoch 6/10: 100%|██████████| 938/938 [00:34<00:00, 27.47batch/s, Loss=0.00233]\n",
      "Epoch 7/10: 100%|██████████| 938/938 [00:33<00:00, 28.36batch/s, Loss=0.00236]\n",
      "Epoch 8/10: 100%|██████████| 938/938 [00:31<00:00, 29.37batch/s, Loss=0.0026] \n",
      "Epoch 9/10: 100%|██████████| 938/938 [00:31<00:00, 29.70batch/s, Loss=0.00241]\n",
      "Epoch 10/10: 100%|██████████| 938/938 [00:32<00:00, 28.98batch/s, Loss=0.00226]\n",
      "Testing: 100%|██████████| 157/157 [00:06<00:00, 23.88batch/s]\n",
      "Epoch 1/10: 100%|██████████| 938/938 [00:33<00:00, 28.03batch/s, Loss=0.0124]\n",
      "Epoch 2/10: 100%|██████████| 938/938 [00:31<00:00, 29.91batch/s, Loss=0.0113] \n",
      "Epoch 3/10: 100%|██████████| 938/938 [00:32<00:00, 28.49batch/s, Loss=0.011]  \n",
      "Epoch 4/10: 100%|██████████| 938/938 [00:33<00:00, 28.21batch/s, Loss=0.01]   \n",
      "Epoch 5/10: 100%|██████████| 938/938 [00:33<00:00, 28.21batch/s, Loss=0.012]  \n",
      "Epoch 6/10: 100%|██████████| 938/938 [00:34<00:00, 26.94batch/s, Loss=0.00991]\n",
      "Epoch 7/10: 100%|██████████| 938/938 [00:33<00:00, 28.23batch/s, Loss=0.0118] \n",
      "Epoch 8/10: 100%|██████████| 938/938 [00:34<00:00, 27.24batch/s, Loss=0.0101] \n",
      "Epoch 9/10: 100%|██████████| 938/938 [00:33<00:00, 27.77batch/s, Loss=0.0111] \n",
      "Epoch 10/10: 100%|██████████| 938/938 [00:34<00:00, 27.05batch/s, Loss=0.00877]\n",
      "Testing: 100%|██████████| 157/157 [00:06<00:00, 24.97batch/s]\n",
      "Epoch 1/10: 100%|██████████| 938/938 [00:32<00:00, 28.53batch/s, Loss=0.0283]\n",
      "Epoch 2/10: 100%|██████████| 938/938 [00:33<00:00, 28.30batch/s, Loss=0.0273]\n",
      "Epoch 3/10: 100%|██████████| 938/938 [00:33<00:00, 27.91batch/s, Loss=0.0266]\n",
      "Epoch 4/10: 100%|██████████| 938/938 [00:34<00:00, 27.41batch/s, Loss=0.0278]\n",
      "Epoch 5/10: 100%|██████████| 938/938 [00:33<00:00, 27.73batch/s, Loss=0.0282]\n",
      "Epoch 6/10: 100%|██████████| 938/938 [00:33<00:00, 27.69batch/s, Loss=0.0274]\n",
      "Epoch 7/10: 100%|██████████| 938/938 [00:34<00:00, 27.00batch/s, Loss=0.025] \n",
      "Epoch 8/10: 100%|██████████| 938/938 [00:34<00:00, 27.53batch/s, Loss=0.0275]\n",
      "Epoch 9/10: 100%|██████████| 938/938 [00:34<00:00, 27.02batch/s, Loss=0.0267]\n",
      "Epoch 10/10: 100%|██████████| 938/938 [00:34<00:00, 27.21batch/s, Loss=0.0227]\n",
      "Testing: 100%|██████████| 157/157 [00:06<00:00, 24.71batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SSIM test scores for different sigma values: [0.9698094446808017, 0.8700647332417271, 0.6852523276026179]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sigmas = [0.1, 0.5, 1.0]  # Different sigma values\n",
    "avg_ssim_scores = []\n",
    "for sigma in sigmas:\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "    train(autoencoder, criterion, optimizer, train_loader, num_epochs=10, sigma=sigma)\n",
    "    avg_ssim_score = test(autoencoder, test_loader, sigma=sigma)\n",
    "    avg_ssim_scores.append(avg_ssim_score)\n",
    "\n",
    "print(\"Average SSIM test scores for different sigma values:\", avg_ssim_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As, it can be seen that with increase in sigma, accuracy of the model is decreasing. This is because, as the noise increases, the model is not able to learn the underlying pattern in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 (Varying Sigma):\n",
    "- As the sigma value increases, the amount of noise added to the images during training also increases.\n",
    "- With higher sigma values, the noise becomes more significant, affecting the reconstruction quality of the autoencoder.\n",
    "- Consequently, the average SSIM test score tends to decrease as sigma increases, indicating lower similarity between the original and reconstructed images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 938/938 [00:30<00:00, 30.60batch/s, Loss=0.0279]\n",
      "Epoch 2/10: 100%|██████████| 938/938 [00:31<00:00, 30.19batch/s, Loss=0.0227]\n",
      "Epoch 3/10: 100%|██████████| 938/938 [00:29<00:00, 31.51batch/s, Loss=0.0227]\n",
      "Epoch 4/10: 100%|██████████| 938/938 [00:31<00:00, 30.17batch/s, Loss=0.0209]\n",
      "Epoch 5/10: 100%|██████████| 938/938 [00:31<00:00, 29.39batch/s, Loss=0.019] \n",
      "Epoch 6/10: 100%|██████████| 938/938 [00:32<00:00, 28.65batch/s, Loss=0.0169]\n",
      "Epoch 7/10: 100%|██████████| 938/938 [00:31<00:00, 30.23batch/s, Loss=0.0196]\n",
      "Epoch 8/10: 100%|██████████| 938/938 [00:30<00:00, 31.06batch/s, Loss=0.0189]\n",
      "Epoch 9/10: 100%|██████████| 938/938 [00:30<00:00, 30.27batch/s, Loss=0.0182]\n",
      "Epoch 10/10: 100%|██████████| 938/938 [00:30<00:00, 30.29batch/s, Loss=0.0166]\n",
      "Testing: 100%|██████████| 157/157 [00:06<00:00, 23.33batch/s]\n",
      "Epoch 1/10: 100%|██████████| 938/938 [00:31<00:00, 30.16batch/s, Loss=0.0162]\n",
      "Epoch 2/10: 100%|██████████| 938/938 [00:31<00:00, 29.96batch/s, Loss=0.0128]\n",
      "Epoch 3/10: 100%|██████████| 938/938 [00:30<00:00, 30.74batch/s, Loss=0.0135] \n",
      "Epoch 4/10: 100%|██████████| 938/938 [00:31<00:00, 29.72batch/s, Loss=0.0115] \n",
      "Epoch 5/10: 100%|██████████| 938/938 [00:30<00:00, 30.73batch/s, Loss=0.00953]\n",
      "Epoch 6/10: 100%|██████████| 938/938 [00:31<00:00, 29.70batch/s, Loss=0.00985]\n",
      "Epoch 7/10: 100%|██████████| 938/938 [00:31<00:00, 29.75batch/s, Loss=0.00966]\n",
      "Epoch 8/10: 100%|██████████| 938/938 [00:31<00:00, 29.62batch/s, Loss=0.00924]\n",
      "Epoch 9/10: 100%|██████████| 938/938 [00:31<00:00, 29.59batch/s, Loss=0.00993]\n",
      "Epoch 10/10: 100%|██████████| 938/938 [00:31<00:00, 29.92batch/s, Loss=0.00737]\n",
      "Testing: 100%|██████████| 157/157 [00:06<00:00, 24.72batch/s]\n",
      "Epoch 1/10: 100%|██████████| 938/938 [00:32<00:00, 28.58batch/s, Loss=0.0108]\n",
      "Epoch 2/10: 100%|██████████| 938/938 [00:32<00:00, 28.57batch/s, Loss=0.00671]\n",
      "Epoch 3/10: 100%|██████████| 938/938 [00:32<00:00, 28.85batch/s, Loss=0.00612]\n",
      "Epoch 4/10: 100%|██████████| 938/938 [00:32<00:00, 28.69batch/s, Loss=0.00547]\n",
      "Epoch 5/10: 100%|██████████| 938/938 [00:32<00:00, 29.07batch/s, Loss=0.00535]\n",
      "Epoch 6/10: 100%|██████████| 938/938 [00:32<00:00, 28.61batch/s, Loss=0.00629]\n",
      "Epoch 7/10: 100%|██████████| 938/938 [00:32<00:00, 29.12batch/s, Loss=0.00488]\n",
      "Epoch 8/10: 100%|██████████| 938/938 [00:33<00:00, 28.06batch/s, Loss=0.00563]\n",
      "Epoch 9/10: 100%|██████████| 938/938 [00:32<00:00, 28.57batch/s, Loss=0.00551]\n",
      "Epoch 10/10: 100%|██████████| 938/938 [00:32<00:00, 28.73batch/s, Loss=0.00512]\n",
      "Testing: 100%|██████████| 157/157 [00:06<00:00, 23.73batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SSIM test scores for different bottleneck dimensionalities: [0.7839948960005227, 0.8993986273019243, 0.9453540767481474]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bottleneck_dims = [8, 16, 32]  # Different bottleneck dimensionality\n",
    "avg_ssim_scores = []\n",
    "sigma = 0.5  # Constant sigma value\n",
    "for dim in bottleneck_dims:\n",
    "    autoencoder = Autoencoder(dim)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "    train(autoencoder, criterion, optimizer, train_loader, num_epochs=10)\n",
    "    avg_ssim_score = test(autoencoder, test_loader)\n",
    "    avg_ssim_scores.append(avg_ssim_score)\n",
    "\n",
    "print(\"Average SSIM test scores for different bottleneck dimensionalities:\", avg_ssim_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With decreasing dimension of bottleneck, accuracy is decreasing. As, the bottleneck dimension decreases, the model is not able to learn the underlying pattern in the data. This is because, the model is not able to learn the important features in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
