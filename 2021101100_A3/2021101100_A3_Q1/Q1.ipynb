{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\n\n\n\n# Transform data to tensors and normalize\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ndef load_cifar_dataset(dataset_name):\n    if dataset_name == \"cifar10\":\n        trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n        testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n    elif dataset_name == \"cifar100\":\n        (trainset, train_labels), (testset, test_labels) = tf.keras.datasets.cifar100.load_data()\n    else:\n        raise ValueError(\"Invalid dataset name. Choose either 'cifar10' or 'cifar100'.\")\n\n    # trainset, valset = train_test_split(trainset, test_size=0.2, random_state=42)\n    \n    return trainset, testset\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-03-25T14:05:02.517198Z","iopub.execute_input":"2024-03-25T14:05:02.517548Z","iopub.status.idle":"2024-03-25T14:05:22.683685Z","shell.execute_reply.started":"2024-03-25T14:05:02.517519Z","shell.execute_reply":"2024-03-25T14:05:22.682734Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-25 14:05:12.514580: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-25 14:05:12.514715: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-25 14:05:12.665104: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T14:05:22.685185Z","iopub.execute_input":"2024-03-25T14:05:22.685755Z","iopub.status.idle":"2024-03-25T14:05:22.737832Z","shell.execute_reply.started":"2024-03-25T14:05:22.685728Z","shell.execute_reply":"2024-03-25T14:05:22.736927Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Using device: cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, trainloader, device, valloader, num_epochs=10):\n    for epoch in range(num_epochs):  # Number of epochs\n        running_loss = 0.0\n        with tqdm(total=len(trainloader), desc=f\"Epoch {epoch+1}/{num_epochs}\", unit='batch') as pbar:\n            \n            for inputs, labels in trainloader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                optimizer.zero_grad()\n\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n                running_loss += loss.item()\n                pbar.update(1)\n        # for inputs, labels in trainloader:\n        #     optimizer.zero_grad()\n\n        #     outputs = model(inputs)\n        #     loss = criterion(outputs, labels)\n        #     loss.backward()\n        #     optimizer.step()\n\n        #     running_loss += loss.item()\n        print(f\"Epoch [{epoch} | {num_epochs}], Training Loss: {running_loss / len(trainloader):.4f}\")\n\n        with torch.no_grad():\n            val_loss = 0\n            acc = 0\n            for inputs, labels in valloader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                predicted = torch.argmax(outputs, dim = 1)\n                acc += len(predicted[predicted == labels]) / len(labels)\n                val_loss += loss.item()\n        print(f\"Epoch [{epoch} | {num_epochs}], Validation Loss: {val_loss / len(valloader):.4f}, Accuracy: {acc / len(valloader):.4f}\")\n\n        \n    \n\n\ndef test_model(model, testloader, device):\n    model.eval()\n    model.to(device)\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in testloader:\n            images, labels = images.to(device), images.to(device)\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    print(f\"Accuracy on test set: {correct / total * 100:.2f}%\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T14:19:56.506174Z","iopub.execute_input":"2024-03-25T14:19:56.506614Z","iopub.status.idle":"2024-03-25T14:19:56.521055Z","shell.execute_reply.started":"2024-03-25T14:19:56.506583Z","shell.execute_reply":"2024-03-25T14:19:56.520024Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self, input_size, hidden_size1, hidden_size2, num_classes):\n        super(MLP, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size1)\n        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n        self.fc3 = nn.Linear(hidden_size2, num_classes)\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        x = x.to(torch.float32)  \n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self, num_classes):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        x = self.pool(torch.relu(self.conv1(x)))\n        x = self.pool(torch.relu(self.conv2(x)))\n        x = x.view(-1, 64 * 8 * 8)\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"batch_size = 4\nnum_epochs = 5\nnum_workers = 2\n\ndataset_name = \"cifar10\"\n\ntrainset, testset = load_cifar_dataset(dataset_name)\ntrainset, valset = train_test_split(trainset, test_size=0.2, random_state=42)\ntrainloader = DataLoader(trainset, batch_size=32, shuffle=True)\nvalloader = DataLoader(valset, batch_size=32, shuffle=True)\ntestloader = DataLoader(testset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T14:09:51.796514Z","iopub.execute_input":"2024-03-25T14:09:51.797265Z","iopub.status.idle":"2024-03-25T14:10:06.870366Z","shell.execute_reply.started":"2024-03-25T14:09:51.797215Z","shell.execute_reply":"2024-03-25T14:10:06.869392Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# MLP","metadata":{}},{"cell_type":"code","source":"input_size = 32 * 32 * 3\nhidden_size1 = 512\nhidden_size2 = 256\nnum_classes = 10\n\nmodel = MLP(input_size, hidden_size1, hidden_size2, num_classes).to(device)\nepochs = 10\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\ntrain_model(model, criterion, optimizer, trainloader, device, valloader, num_epochs=epochs)\n\n","metadata":{"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","output_type":"stream","text":"Epoch [0 | 10], Training Loss: 1.6796\n\nEpoch [0 | 10], Validation Loss: 1.5803, Accuracy: 0.4394\n\nEpoch [1 | 10], Training Loss: 1.4802\n\nEpoch [1 | 10], Validation Loss: 1.4927, Accuracy: 0.4715\n\nEpoch [2 | 10], Training Loss: 1.3729\n\nEpoch [2 | 10], Validation Loss: 1.4606, Accuracy: 0.4901\n\nEpoch [3 | 10], Training Loss: 1.2921\n\nEpoch [3 | 10], Validation Loss: 1.4572, Accuracy: 0.4957\n\nEpoch [4 | 10], Training Loss: 1.2039\n\nEpoch [4 | 10], Validation Loss: 1.4337, Accuracy: 0.5007\n\nEpoch [5 | 10], Training Loss: 1.1302\n\nEpoch [5 | 10], Validation Loss: 1.4754, Accuracy: 0.5092\n\nEpoch [6 | 10], Training Loss: 1.0581\n\nEpoch [6 | 10], Validation Loss: 1.5367, Accuracy: 0.4997\n\nEpoch [7 | 10], Training Loss: 0.9887\n\nEpoch [7 | 10], Validation Loss: 1.5478, Accuracy: 0.5038\n\nEpoch [8 | 10], Training Loss: 0.9191\n\nEpoch [8 | 10], Validation Loss: 1.5882, Accuracy: 0.5085\n\nEpoch [9 | 10], Training Loss: 0.8608\n\nEpoch [9 | 10], Validation Loss: 1.6633, Accuracy: 0.5030\n"}]},{"cell_type":"code","source":"model = CNN(num_classes).to(device)\nepochs = 10\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\ntrain_model(model, criterion, optimizer, trainloader, device, valloader, num_epochs=epochs)\n\n","metadata":{},"execution_count":60,"outputs":[{"name":"stdout","output_type":"stream","text":"Epoch [0 | 10], Training Loss: 1.2900\n\nEpoch [0 | 10], Validation Loss: 0.9865, Accuracy: 0.6551\n\nEpoch [1 | 10], Training Loss: 0.8892\n\nEpoch [1 | 10], Validation Loss: 0.8925, Accuracy: 0.6952\n\nEpoch [2 | 10], Training Loss: 0.6719\n\nEpoch [2 | 10], Validation Loss: 0.8269, Accuracy: 0.7168\n\nEpoch [3 | 10], Training Loss: 0.4773\n\nEpoch [3 | 10], Validation Loss: 0.8614, Accuracy: 0.7259\n\nEpoch [4 | 10], Training Loss: 0.3011\n\nEpoch [4 | 10], Validation Loss: 1.0001, Accuracy: 0.7111\n\nEpoch [5 | 10], Training Loss: 0.1716\n\nEpoch [5 | 10], Validation Loss: 1.1576, Accuracy: 0.7232\n\nEpoch [6 | 10], Training Loss: 0.1229\n\nEpoch [6 | 10], Validation Loss: 1.3097, Accuracy: 0.7156\n\nEpoch [7 | 10], Training Loss: 0.0895\n\nEpoch [7 | 10], Validation Loss: 1.4488, Accuracy: 0.7151\n\nEpoch [8 | 10], Training Loss: 0.0791\n\nEpoch [8 | 10], Validation Loss: 1.5372, Accuracy: 0.7174\n\nEpoch [9 | 10], Training Loss: 0.0663\n\nEpoch [9 | 10], Validation Loss: 1.6297, Accuracy: 0.7148\n"}]},{"cell_type":"code","source":"from torchvision.models import vgg16, vgg19\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T14:06:20.868683Z","iopub.execute_input":"2024-03-25T14:06:20.869082Z","iopub.status.idle":"2024-03-25T14:06:20.874000Z","shell.execute_reply.started":"2024-03-25T14:06:20.869050Z","shell.execute_reply":"2024-03-25T14:06:20.872691Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"vgg_model = vgg19(pretrained=True).to(device)\n# Freeze all layers\nfor param in vgg_model.parameters():\n    param.requires_grad = False\n    \nfor param in vgg_model.features.parameters():\n    param.requires_grad = True\n\nnum_features = vgg_model.classifier[6].in_features\nvgg_model.classifier[6] = nn.Linear(num_features, 10)  # Assuming 10 classes for CIFAR-10\nvgg_model = vgg_model.to(device)\nepochs = 10 \n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(vgg_model.parameters(), lr=0.001, momentum=0.9)\n\ntrain_model(vgg_model, criterion, optimizer, trainloader, device, valloader, num_epochs=epochs)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T14:48:22.328418Z","iopub.execute_input":"2024-03-25T14:48:22.329084Z","iopub.status.idle":"2024-03-25T14:55:45.428176Z","shell.execute_reply.started":"2024-03-25T14:48:22.329053Z","shell.execute_reply":"2024-03-25T14:55:45.427065Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Epoch 1/10: 100%|██████████| 1250/1250 [00:40<00:00, 30.51batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [0 | 10], Training Loss: 0.7322\nEpoch [0 | 10], Validation Loss: 0.5711, Accuracy: 0.8069\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 100%|██████████| 1250/1250 [00:39<00:00, 31.44batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1 | 10], Training Loss: 0.4047\nEpoch [1 | 10], Validation Loss: 0.4500, Accuracy: 0.8550\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10: 100%|██████████| 1250/1250 [00:40<00:00, 31.08batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2 | 10], Training Loss: 0.2842\nEpoch [2 | 10], Validation Loss: 0.4684, Accuracy: 0.8543\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10: 100%|██████████| 1250/1250 [00:40<00:00, 31.24batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3 | 10], Training Loss: 0.1983\nEpoch [3 | 10], Validation Loss: 0.4169, Accuracy: 0.8734\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10: 100%|██████████| 1250/1250 [00:40<00:00, 31.15batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4 | 10], Training Loss: 0.1421\nEpoch [4 | 10], Validation Loss: 0.4320, Accuracy: 0.8789\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10: 100%|██████████| 1250/1250 [00:40<00:00, 31.18batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5 | 10], Training Loss: 0.0986\nEpoch [5 | 10], Validation Loss: 0.4534, Accuracy: 0.8789\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10: 100%|██████████| 1250/1250 [00:40<00:00, 31.24batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [6 | 10], Training Loss: 0.0706\nEpoch [6 | 10], Validation Loss: 0.5319, Accuracy: 0.8740\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10: 100%|██████████| 1250/1250 [00:40<00:00, 31.18batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [7 | 10], Training Loss: 0.0670\nEpoch [7 | 10], Validation Loss: 0.4622, Accuracy: 0.8842\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10: 100%|██████████| 1250/1250 [00:40<00:00, 31.12batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [8 | 10], Training Loss: 0.0443\nEpoch [8 | 10], Validation Loss: 0.4971, Accuracy: 0.8838\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10: 100%|██████████| 1250/1250 [00:40<00:00, 31.11batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [9 | 10], Training Loss: 0.0425\nEpoch [9 | 10], Validation Loss: 0.5497, Accuracy: 0.8811\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}